# -*- coding: utf-8 -*-
"""Assistente_voz

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NQUtiTU3h7Dey8wM0hlePSIlVoYhvTTR
"""

!pip install SpeechRecognition gradio pydub openai requests


import speech_recognition as sr
import gradio as gr
from pydub import AudioSegment
import openai
import webbrowser
import requests
from datetime import datetime


openai.api_key = ''
weather_api_key = ''


def get_weather(city="São Paulo"):
    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={weather_api_key}&lang=pt_br&units=metric"
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        temp = data['main']['temp']
        description = data['weather'][0]['description']
        return f"A temperatura em {city} é {temp}°C com {description}."
    else:
        return "Não consegui consultar o clima no momento."


conversation_history = []

def recognize_and_execute(audio):

    audio = AudioSegment.from_file(audio)
    audio.export("audio.wav", format="wav")


    recognizer = sr.Recognizer()


    with sr.AudioFile("audio.wav") as source:
        audio_data = recognizer.record(source)
        try:

            text = recognizer.recognize_google(audio_data, language='pt-BR').lower()


            if "abrir navegador" in text:
                webbrowser.open("https://www.google.com")
                return "Comando reconhecido: Abrindo o navegador."

            elif "abrir calculadora" in text:
                webbrowser.open("https://www.calculator.com")
                return "Comando reconhecido: Abrindo a calculadora online."

            elif "consultar temperatura" in text:
                return get_weather()

            elif "que horas são" in text:
                now = datetime.now()
                current_time = now.strftime("%H:%M")
                return f"Agora são {current_time}."

            elif "tocar música" in text:
                webbrowser.open("https://www.youtube.com/results?search_query=música")
                return "Abrindo o YouTube para tocar música."

            elif "ok ia" in text:
                return "Comando de ativação reconhecido: Estou ouvindo seus comandos."

            else:

                conversation_history.append(f"Usuário: {text}")
                context = "\n".join(conversation_history[-5:])
                response = openai.Completion.create(
                    engine="text-davinci-003",
                    prompt=f"{context}\nAssistente:",
                    max_tokens=150
                )
                reply = response.choices[0].text.strip()
                conversation_history.append(f"Assistente: {reply}")
                return f"Chatbot respondeu: {reply}"

        except sr.UnknownValueError:
            return "Não consegui entender o que você disse."
        except sr.RequestError as e:
            return f"Erro na solicitação: {e}"


interface = gr.Interface(
    fn=recognize_and_execute,
    inputs=gr.Audio(type="filepath"),
    outputs="text",
    title="Assistente de Voz Avançado com Python e OpenAI",
    description="Diga comandos como 'Abrir navegador', 'Consultar temperatura', 'Que horas são' ou interaja com um chatbot da OpenAI. Ative o assistente com 'Ok IA'."
)


interface.launch()